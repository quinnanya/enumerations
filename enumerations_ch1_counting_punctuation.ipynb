{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerations: Chapter 1: counting punctuation (notebook version)\n",
    "This R notebook is an adaptation of code published by Andrew Piper in the [GitHub repo accompanying his 2018 book](https://github.com/piperandrew/enumerations), *Enumerations: Data and Literary Study*.\n",
    "\n",
    "It was adapted by Quinn Dombrowski, who doesn't know any R, using similar data. Andrew Piper extensively commented the original code, but Quinn restructured it as markdown cells in this notebook, and created the paratextual structure, comments on the source data, and other comments geared towards people who don't really know R.\n",
    "\n",
    "The functionality of the notebook was made possible by Shawn Graham, who diagnosed some of the errors Quinn encountered (and complained about on Twitter) and found solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and load packages\n",
    "The code cell below installs the prerequisite R packages. The second code cell loads them in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('tm', repos='http://cran.us.r-project.org')\n",
    "install.packages('SnowballC', repos='http://cran.us.r-project.org')\n",
    "install.packages('splitstackshape', repos='http://cran.us.r-project.org')\n",
    "install.packages('gridExtra', repos='http://cran.us.r-project.org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(stringr)\n",
    "library(tm)\n",
    "library(SnowballC)\n",
    "library(zoo)\n",
    "library(splitstackshape)\n",
    "library(ggplot2)\n",
    "library(scales)\n",
    "library(gridExtra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data\n",
    "This code assumes that you have a directory full of .txt files that represent a corpus of poetry. The file name for each .txt file should be as follows: *NumericalUniqueID_AuthorLastNameAuthorFirstName_PoemTitle_PublishedYear.txt*. \n",
    "\n",
    "For example: `66005_AliAghaShahid_Ghazal_1949.txt`.\n",
    "\n",
    "Each .txt file in the intended source material has the line number on the line above the text, and the text is indented by a tab. For instance:\n",
    "\n",
    "`1\n",
    "\tThere once was a man from Nantucket\n",
    "2\n",
    "\tWho kept all his cash in a bucket.\n",
    "3\n",
    "\tBut his daughter, named Nan,\n",
    "4\n",
    "\tRan away with a man\n",
    "5\n",
    "\tAnd as for the bucket, Nantucket.`\n",
    "    \n",
    "You don't necessarily have to structure your text this way, but if you don't, there's some lines below (e.g. `no.lines<-(length(work2)/2)-1` and `work.word.vector<-gsub(\"\\\\d\", \"\", work.word.vector) #remove numbers`) that you'd need to modify to accommodate the lack of line numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Counting punctuation marks\n",
    "\n",
    "This section counts punctuation marks by word and line (if poems have line breaks) for either a group of works or a single work that has been divided into smaller chunks it does not record all punctuation marks, but limits itself to a small set of primary marks:\n",
    "\n",
    "- these include: ?, !, ., , ;, : ()\n",
    "\n",
    "It takes as input a directory of works and outputs a table of marks per word/line\n",
    "\n",
    "This is the code used to extract punctuation from the following data sets (as defined by Andrew Piper):\n",
    "\n",
    "- [txtLAB450](https://txtlab.org/2016/01/txtlab450-a-data-set-of-multilingual-novels-for-teaching-and-research/)\n",
    "- Novel_19C: 3,285 novels in English published between 1800 and 1899, collected by the [Stanford Literary Lab](https://litlab.stanford.edu/)\n",
    "- Novel_20C: a random selection of 24,400 pairs of pages from novels published since 1950.\n",
    "- Poetry_19C: 125,675 poems in English written by authors born between 1765 and 1865, drawn from the ProQuest Literature Online Collection.\n",
    "- Poetry_20C: 75,297 poems in English witten by authors born between 1865 an 1975, drawn from the ProQuest Literature Online Collection.\n",
    "\n",
    "The code is presented for use on other data sets.\n",
    "\n",
    "Turn off lines related to \"line breaks\" for non-poetry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load data\n",
    "Below, put the full path to the directory that contains your corpus of texts, in place of `20CPoetryAll`.\n",
    "\n",
    "For instance, the path to a Texts folder in the default Documents directory is (substituting your user name on the computer for YOUR-USER-NAME):\n",
    "\n",
    "- On Mac: '/Users/YOUR-USER-NAME/Documents/Texts'\n",
    "- On Windows: 'C:\\\\\\Users\\\\\\YOUR-USER-NAME\\\\\\Documents\\\\\\Texts'\n",
    "\n",
    "*Note:* The code cell below is modified from the source repo. There were issues in opening the files when `full.names` were set to false. Thanks to Shawn Graham for figuring out the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames<-list.files(\"/Users/qad/20CPoetryAll\", pattern=\"*.txt\", full.names=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Analyze data\n",
    "The following cell block analyzes the data, according to the comments embedded in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation.dtm<-NULL\n",
    "for (i in 1:length(filenames)) {\n",
    "  #load poem\n",
    "  work<-scan(filenames[i], what=\"character\", quote=\"\")\n",
    "  #load second version separating by line breaks\n",
    "  work2<-scan(filenames[i], what=\"character\", quote=\"\", sep = \"\\n\")\n",
    "  if (length(work) > 0){\n",
    "    no.lines<-(length(work2)/2)-1\n",
    "    punct<-grep(\"\\\\...|\\\\!|\\\\.|\\\\,|\\\\;|\\\\:|\\\\(|\\\\)\", work)\n",
    "    work.punct<-str_extract(work, \"\\\\...|\\\\!|\\\\.|\\\\,|\\\\;|\\\\:|\\\\(|\\\\)\")\n",
    "    punct2<-work.punct[!is.na(work.punct)]\n",
    "    #calculate total words\n",
    "    work.lower<-tolower(work) # all lower case\n",
    "    work.words<-strsplit(work.lower, \"\\\\W\") # turn into a list of words\n",
    "    work.word.vector<-unlist(work.words) #turn into a vector\n",
    "    work.word.vector<-gsub(\"\\\\d\", \"\", work.word.vector) #remove numbers\n",
    "    work.word.vector<-work.word.vector[which(work.word.vector!=\"\")]#only keeps parts of vector with words\n",
    "    total.words<-length(work.word.vector) #total words in the novel\n",
    "    #frequency of a given punctuation mark\n",
    "    ellipsis<-length(grep(\"\\\\...\", punct2))/total.words\n",
    "    ellipsis.line<-length(grep(\"\\\\...\", punct2))/no.lines\n",
    "    exclam<-length(grep(\"\\\\!\", punct2))/total.words\n",
    "    exclam.line<-length(grep(\"\\\\!\", punct2))/no.lines\n",
    "    period<-length(grep(\"\\\\.\", punct2))/total.words\n",
    "    period.line<-length(grep(\"\\\\.\", punct2))/no.lines\n",
    "    comma<-length(grep(\"\\\\,\", punct2))/total.words\n",
    "    comma.line<-length(grep(\"\\\\,\", punct2))/no.lines\n",
    "    total<-length(punct)/total.words\n",
    "    total.line<-length(punct)/no.lines\n",
    "    #novel.dtm<-data.frame(filenames[i], total.words,ellipsis, exclam, period, comma, total)\n",
    "    novel.dtm<-data.frame(filenames[i], total.words, no.lines, ellipsis, ellipsis.line, exclam, exclam.line, period, period.line, comma, comma.line, total, total.line)\n",
    "    punctuation.dtm<-rbind(punctuation.dtm, novel.dtm)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Output results\n",
    "The following cell block creates an output file with the results of the cell above, named `punctuationoutput.csv`. This file will, by defualt, be created in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(punctuation.dtm, file = \"punctuationoutput.csv\",row.names=FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
